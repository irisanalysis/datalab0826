#!/usr/bin/env python3
"""
SaaSæ•°æ®åˆ†æå¹³å°è´¨é‡è¯„ä¼°å·¥å…·
æ£€æŸ¥ä»£ç è´¨é‡ã€æµ‹è¯•è¦†ç›–ç‡ã€æ€§èƒ½å’Œå®‰å…¨æ€§
"""

import os
import sys
import subprocess
import json
import time
from pathlib import Path

class QualityAssessment:
    """è´¨é‡è¯„ä¼°ä¸»ç±»"""
    
    def __init__(self):
        self.project_root = Path("/home/user/datalab0826")
        self.results = {}
        
    def check_file_structure(self):
        """æ£€æŸ¥é¡¹ç›®æ–‡ä»¶ç»“æ„"""
        print("ğŸ“ æ£€æŸ¥é¡¹ç›®æ–‡ä»¶ç»“æ„...")
        
        required_files = {
            "main.py": "ä¸»åº”ç”¨æ–‡ä»¶",
            "requirements.txt": "Pythonä¾èµ–",
            "devserver.sh": "å¼€å‘æœåŠ¡å™¨è„šæœ¬", 
            "pyproject.toml": "é¡¹ç›®é…ç½®",
            ".env.example": "ç¯å¢ƒå˜é‡æ¨¡æ¿",
            "docker/docker-compose.yml": "Dockeré…ç½®"
        }
        
        missing_files = []
        existing_files = []
        
        for file_path, description in required_files.items():
            full_path = self.project_root / file_path
            if full_path.exists():
                existing_files.append((file_path, description))
                print(f"  âœ… {file_path} - {description}")
            else:
                missing_files.append((file_path, description))
                print(f"  âŒ {file_path} - {description}")
                
        self.results["file_structure"] = {
            "existing": len(existing_files),
            "missing": len(missing_files),
            "score": len(existing_files) / len(required_files) * 100
        }
        
        return len(missing_files) == 0
        
    def check_documentation(self):
        """æ£€æŸ¥æ–‡æ¡£å®Œæ•´æ€§"""
        print("\nğŸ“š æ£€æŸ¥æ–‡æ¡£å®Œæ•´æ€§...")
        
        doc_files = {
            "docs/PRD/saas_platform_prd.md": "äº§å“éœ€æ±‚æ–‡æ¡£",
            "docs/system_architecture.md": "ç³»ç»Ÿæ¶æ„æ–‡æ¡£", 
            "docs/frontend_architecture.md": "å‰ç«¯æ¶æ„æ–‡æ¡£",
            "docs/ui_design_system.md": "UIè®¾è®¡ç³»ç»Ÿ",
            "docs/brand_guidelines.md": "å“ç‰ŒæŒ‡å—",
            "docs/ux_research_report.md": "UXç ”ç©¶æŠ¥å‘Š",
            "docs/visual_storytelling_guide.md": "è§†è§‰å™äº‹æŒ‡å—",
            "docs/whimsy_interaction_guide.md": "äº¤äº’è®¾è®¡æŒ‡å—",
            "docs/analytics_professional_assessment.md": "ä¸“ä¸šæ€§è¯„ä¼°æŠ¥å‘Š"
        }
        
        existing_docs = []
        missing_docs = []
        
        for doc_path, description in doc_files.items():
            full_path = self.project_root / doc_path
            if full_path.exists():
                existing_docs.append(doc_path)
                print(f"  âœ… {doc_path}")
            else:
                missing_docs.append(doc_path)
                print(f"  âŒ {doc_path}")
                
        self.results["documentation"] = {
            "existing": len(existing_docs),
            "missing": len(missing_docs), 
            "score": len(existing_docs) / len(doc_files) * 100
        }
        
        return len(missing_docs) == 0
        
    def check_code_quality(self):
        """æ£€æŸ¥ä»£ç è´¨é‡"""
        print("\nğŸ” æ£€æŸ¥ä»£ç è´¨é‡...")
        
        # æ£€æŸ¥Pythonæ–‡ä»¶
        python_files = list(self.project_root.glob("*.py"))
        
        quality_metrics = {
            "python_files": len(python_files),
            "large_files": 0,
            "has_docstrings": 0,
            "has_type_hints": 0
        }
        
        for py_file in python_files:
            try:
                with open(py_file, 'r', encoding='utf-8') as f:
                    content = f.read()
                    lines = content.split('\n')
                    
                    # æ£€æŸ¥æ–‡ä»¶å¤§å°
                    if len(lines) > 500:
                        quality_metrics["large_files"] += 1
                        print(f"  âš ï¸  {py_file.name} æ–‡ä»¶è¾ƒå¤§ ({len(lines)} è¡Œ)")
                    
                    # æ£€æŸ¥æ–‡æ¡£å­—ç¬¦ä¸²
                    if '"""' in content or "'''" in content:
                        quality_metrics["has_docstrings"] += 1
                        
                    # æ£€æŸ¥ç±»å‹æç¤º
                    if ":" in content and ("->" in content or "typing" in content):
                        quality_metrics["has_type_hints"] += 1
                        
            except Exception as e:
                print(f"  âŒ æ— æ³•åˆ†æ {py_file.name}: {e}")
                
        # è®¡ç®—è´¨é‡å¾—åˆ†
        if quality_metrics["python_files"] > 0:
            docstring_score = quality_metrics["has_docstrings"] / quality_metrics["python_files"] * 100
            type_hint_score = quality_metrics["has_type_hints"] / quality_metrics["python_files"] * 100
            
            print(f"  ğŸ“Š Pythonæ–‡ä»¶æ•°é‡: {quality_metrics['python_files']}")
            print(f"  ğŸ“ æ–‡æ¡£å­—ç¬¦ä¸²è¦†ç›–ç‡: {docstring_score:.1f}%")
            print(f"  ğŸ·ï¸  ç±»å‹æç¤ºè¦†ç›–ç‡: {type_hint_score:.1f}%")
            
            self.results["code_quality"] = {
                "files": quality_metrics["python_files"],
                "docstring_coverage": docstring_score,
                "type_hint_coverage": type_hint_score,
                "score": (docstring_score + type_hint_score) / 2
            }
        else:
            self.results["code_quality"] = {"score": 0}
            
    def check_security_basics(self):
        """æ£€æŸ¥åŸºæœ¬å®‰å…¨é…ç½®"""
        print("\nğŸ”’ æ£€æŸ¥å®‰å…¨é…ç½®...")
        
        security_checks = {
            ".env in .gitignore": False,
            "JWT secret configured": False, 
            "Password hashing": False,
            "HTTPS configuration": False
        }
        
        # æ£€æŸ¥.gitignore
        gitignore_path = self.project_root / ".gitignore"
        if gitignore_path.exists():
            with open(gitignore_path, 'r') as f:
                gitignore_content = f.read()
                if ".env" in gitignore_content:
                    security_checks[".env in .gitignore"] = True
                    print("  âœ… .envæ–‡ä»¶å·²åŠ å…¥.gitignore")
                else:
                    print("  âš ï¸  .envæ–‡ä»¶æœªåŠ å…¥.gitignore")
        
        # æ£€æŸ¥main.pyä¸­çš„å®‰å…¨é…ç½®
        main_py = self.project_root / "main.py"
        if main_py.exists():
            with open(main_py, 'r') as f:
                content = f.read()
                
                if "JWT_SECRET_KEY" in content:
                    security_checks["JWT secret configured"] = True
                    print("  âœ… JWTå¯†é’¥å·²é…ç½®")
                    
                if "bcrypt" in content or "werkzeug.security" in content:
                    security_checks["Password hashing"] = True
                    print("  âœ… å¯†ç å“ˆå¸Œå·²å®ç°")
                    
        passed_checks = sum(security_checks.values())
        total_checks = len(security_checks)
        
        self.results["security"] = {
            "passed": passed_checks,
            "total": total_checks,
            "score": passed_checks / total_checks * 100
        }
        
        print(f"  ğŸ“Š å®‰å…¨æ£€æŸ¥é€šè¿‡: {passed_checks}/{total_checks}")
        
    def check_performance_config(self):
        """æ£€æŸ¥æ€§èƒ½é…ç½®"""
        print("\nâš¡ æ£€æŸ¥æ€§èƒ½é…ç½®...")
        
        performance_indicators = {
            "Database indexing": False,
            "Caching configured": False,
            "Static file serving": False,
            "Compression enabled": False
        }
        
        # æ£€æŸ¥main.pyä¸­çš„æ€§èƒ½é…ç½®
        main_py = self.project_root / "main.py"
        if main_py.exists():
            with open(main_py, 'r') as f:
                content = f.read()
                
                if "Index" in content or "index=" in content:
                    performance_indicators["Database indexing"] = True
                    print("  âœ… æ•°æ®åº“ç´¢å¼•å·²é…ç½®")
                    
                if "cache" in content.lower():
                    performance_indicators["Caching configured"] = True
                    print("  âœ… ç¼“å­˜å·²é…ç½®")
                    
                if "static" in content.lower():
                    performance_indicators["Static file serving"] = True
                    print("  âœ… é™æ€æ–‡ä»¶æœåŠ¡å·²é…ç½®")
        
        passed_checks = sum(performance_indicators.values())
        total_checks = len(performance_indicators)
        
        self.results["performance"] = {
            "passed": passed_checks,
            "total": total_checks,
            "score": passed_checks / total_checks * 100
        }
        
    def run_tests(self):
        """è¿è¡Œæµ‹è¯•å¥—ä»¶"""
        print("\nğŸ§ª è¿è¡Œæµ‹è¯•å¥—ä»¶...")
        
        test_files = [
            "test_comprehensive_saas.py",
            "test_saas_api.py",
            "tests/test_api.sh",
            "tests/test_e2e.sh"
        ]
        
        available_tests = []
        for test_file in test_files:
            test_path = self.project_root / test_file
            if test_path.exists():
                available_tests.append(test_file)
                print(f"  âœ… {test_file} å­˜åœ¨")
            else:
                print(f"  âŒ {test_file} ä¸å­˜åœ¨")
        
        self.results["testing"] = {
            "available_tests": len(available_tests),
            "total_tests": len(test_files),
            "score": len(available_tests) / len(test_files) * 100
        }
        
        # å¦‚æœpytestå¯ç”¨ï¼Œå°è¯•è¿è¡ŒPythonæµ‹è¯•
        if "test_comprehensive_saas.py" in available_tests:
            try:
                print("  ğŸ”„ è¿è¡ŒPythonæµ‹è¯•...")
                result = subprocess.run(
                    [sys.executable, "test_comprehensive_saas.py"],
                    cwd=self.project_root,
                    capture_output=True,
                    text=True,
                    timeout=30
                )
                print("  âœ… æµ‹è¯•æ‰§è¡Œå®Œæˆ")
            except Exception as e:
                print(f"  âš ï¸  æµ‹è¯•æ‰§è¡Œå¤±è´¥: {e}")
                
    def generate_overall_score(self):
        """è®¡ç®—æ€»ä½“è´¨é‡å¾—åˆ†"""
        print("\nğŸ“Š è´¨é‡è¯„ä¼°æ€»ç»“")
        print("=" * 50)
        
        weights = {
            "file_structure": 0.15,
            "documentation": 0.25,
            "code_quality": 0.20,
            "security": 0.20,
            "performance": 0.10,
            "testing": 0.10
        }
        
        total_score = 0
        for category, weight in weights.items():
            if category in self.results:
                score = self.results[category].get("score", 0)
                weighted_score = score * weight
                total_score += weighted_score
                
                print(f"{category:15}: {score:5.1f}% (æƒé‡: {weight:.0%}) = {weighted_score:5.1f}")
            else:
                print(f"{category:15}: æœªè¯„ä¼°")
                
        print("-" * 50)
        print(f"{'æ€»ä½“å¾—åˆ†':15}: {total_score:5.1f}%")
        
        # è¯„çº§
        if total_score >= 90:
            grade = "A+ (ä¼˜ç§€)"
        elif total_score >= 80:
            grade = "A  (è‰¯å¥½)"
        elif total_score >= 70:
            grade = "B+ (ä¸­ç­‰åä¸Š)"
        elif total_score >= 60:
            grade = "B  (ä¸­ç­‰)"
        else:
            grade = "C  (éœ€è¦æ”¹è¿›)"
            
        print(f"{'è´¨é‡è¯„çº§':15}: {grade}")
        
        self.results["overall"] = {
            "score": total_score,
            "grade": grade
        }
        
        return total_score
        
    def generate_recommendations(self):
        """ç”Ÿæˆæ”¹è¿›å»ºè®®"""
        print("\nğŸ’¡ æ”¹è¿›å»ºè®®")
        print("=" * 50)
        
        recommendations = []
        
        # åŸºäºç»“æœç”Ÿæˆå»ºè®®
        if self.results.get("file_structure", {}).get("score", 0) < 100:
            recommendations.append("å®Œå–„é¡¹ç›®æ–‡ä»¶ç»“æ„ï¼Œç¡®ä¿æ‰€æœ‰å¿…è¦æ–‡ä»¶å­˜åœ¨")
            
        if self.results.get("documentation", {}).get("score", 0) < 80:
            recommendations.append("å®Œå–„é¡¹ç›®æ–‡æ¡£ï¼Œç‰¹åˆ«æ˜¯APIæ–‡æ¡£å’Œéƒ¨ç½²æŒ‡å—")
            
        if self.results.get("code_quality", {}).get("score", 0) < 70:
            recommendations.append("æé«˜ä»£ç è´¨é‡ï¼šæ·»åŠ æ–‡æ¡£å­—ç¬¦ä¸²å’Œç±»å‹æç¤º")
            
        if self.results.get("security", {}).get("score", 0) < 90:
            recommendations.append("åŠ å¼ºå®‰å…¨é…ç½®ï¼šHTTPSã€å¯†é’¥ç®¡ç†ã€è¾“å…¥éªŒè¯")
            
        if self.results.get("testing", {}).get("score", 0) < 80:
            recommendations.append("å®Œå–„æµ‹è¯•å¥—ä»¶ï¼Œæé«˜æµ‹è¯•è¦†ç›–ç‡")
            
        if recommendations:
            for i, rec in enumerate(recommendations, 1):
                print(f"{i}. {rec}")
        else:
            print("ğŸ‰ é¡¹ç›®è´¨é‡è‰¯å¥½ï¼Œæ— é‡è¦æ”¹è¿›å»ºè®®ï¼")
            
    def save_report(self):
        """ä¿å­˜è¯„ä¼°æŠ¥å‘Š"""
        report_path = self.project_root / "quality_assessment_report.json"
        
        with open(report_path, 'w', encoding='utf-8') as f:
            json.dump(self.results, f, indent=2, ensure_ascii=False)
            
        print(f"\nğŸ“„ è¯¦ç»†æŠ¥å‘Šå·²ä¿å­˜è‡³: {report_path}")
        
    def run_full_assessment(self):
        """è¿è¡Œå®Œæ•´çš„è´¨é‡è¯„ä¼°"""
        print("ğŸš€ å¼€å§‹SaaSå¹³å°è´¨é‡è¯„ä¼°")
        print("=" * 50)
        
        # è¿è¡Œå„é¡¹æ£€æŸ¥
        self.check_file_structure()
        self.check_documentation()
        self.check_code_quality()
        self.check_security_basics()
        self.check_performance_config()
        self.run_tests()
        
        # ç”Ÿæˆæ€»ç»“
        overall_score = self.generate_overall_score()
        self.generate_recommendations()
        self.save_report()
        
        print("\nâœ… è´¨é‡è¯„ä¼°å®Œæˆï¼")
        
        return overall_score

def main():
    """ä¸»å‡½æ•°"""
    assessor = QualityAssessment()
    score = assessor.run_full_assessment()
    
    # æ ¹æ®å¾—åˆ†è®¾ç½®é€€å‡ºç 
    if score >= 80:
        sys.exit(0)  # ä¼˜ç§€/è‰¯å¥½
    elif score >= 60:
        sys.exit(1)  # ä¸­ç­‰ï¼Œéœ€è¦å…³æ³¨
    else:
        sys.exit(2)  # éœ€è¦é‡å¤§æ”¹è¿›

if __name__ == "__main__":
    main()